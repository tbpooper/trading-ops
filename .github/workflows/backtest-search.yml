name: backtest-search

on:
  workflow_dispatch:
  push:
    branches: [main]
  schedule:
    # Run frequently so results keep updating without manual clicks.
    # Twice per hour at :05 and :35 UTC.
    - cron: '5,35 * * * *'

concurrency:
  group: backtest-search
  cancel-in-progress: true

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        family: [v8]
        seed: [1337, 2021, 404, 777]

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt || true

      - name: Download data (MNQ 5m)
        run: |
          set -e
          mkdir -p trading/data/inbound

          # Robust download (GitHub sometimes returns an HTML error page).
          url="https://github.com/tbpooper/trading-ops/releases/download/data-v1/mnq1_5m_tv_unix.csv"
          out="trading/data/inbound/mnq1_5m_tv_unix.csv"

          curl --fail --location --retry 5 --retry-delay 2 --connect-timeout 10 \
            -o "$out" "$url"

          # Validate header contains TradingView-style columns.
          python - <<'PY'
          import csv
          p = "trading/data/inbound/mnq1_5m_tv_unix.csv"
          with open(p, newline='') as f:
            r = csv.DictReader(f)
            assert r.fieldnames, "missing header"
            want = {"time","open","high","low","close"}
            missing = want - set([h.strip().lower() for h in r.fieldnames])
            assert not missing, f"bad csv header; missing {sorted(missing)}; got={r.fieldnames[:10]}"
          print("data_ok")
          PY

      - name: Run search (bounded)
        env:
          PYTHONPATH: .
          DATA_CSV: trading/data/inbound/mnq1_5m_tv_unix.csv
          MAX_SECONDS: 1500
          SEED: ${{ matrix.seed }}
          FAMILY: ${{ matrix.family }}
        run: |
          python trading/backtest_harness/run_actions_search.py

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: backtest-artifacts-${{ matrix.family }}-${{ matrix.seed }}
          path: artifacts/

  aggregate:
    runs-on: ubuntu-latest
    needs: [run]
    timeout-minutes: 10
    permissions:
      contents: write

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Aggregate results
        run: |
          python trading/backtest_harness/aggregate_artifacts.py

      - name: Commit results to repo
        run: |
          set -e
          git config user.name "clawdbot-actions"
          git config user.email "clawdbot-actions@users.noreply.github.com"
          git add results/latest_best.json results/latest_table.json
          git commit -m "Update latest backtest results" || exit 0

          # Rebase + retry push to avoid races with other commits to main
          for i in 1 2 3; do
            git pull --rebase
            if git push; then
              exit 0
            fi
            sleep 3
          done
          exit 1
